\relax 
\providecommand\zref@newlabel[2]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global/global}
\providecommand \oddpage@label [2]{}
\babel@aux{french}{}
\pgfsyspdfmark {pgfid1}{4661699}{24655201}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\abx@aux@cite{0}{10.5555/3312046}
\abx@aux@segm{0}{0}{10.5555/3312046}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Contexte}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Modélisation}{2}{section.2.1}\protected@file@percent }
\abx@aux@backref{1}{10.5555/3312046}{0}{2}{2}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}TD Learning}{2}{section.2.2}\protected@file@percent }
\abx@aux@cite{0}{sutton1999policygradientmethodsreinforcement}
\abx@aux@segm{0}{0}{sutton1999policygradientmethodsreinforcement}
\abx@aux@cite{0}{thrun1993issuesactionselection}
\abx@aux@segm{0}{0}{thrun1993issuesactionselection}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Méthode de Policy Gradient}{3}{section.2.3}\protected@file@percent }
\abx@aux@backref{2}{sutton1999policygradientmethodsreinforcement}{0}{3}{3}
\abx@aux@cite{0}{hasselt2010doubleqlearning}
\abx@aux@segm{0}{0}{hasselt2010doubleqlearning}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Biais d'estimation}{4}{section.2.4}\protected@file@percent }
\abx@aux@backref{3}{thrun1993issuesactionselection}{0}{4}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Biais de maximisation}{4}{subsection.2.4.1}\protected@file@percent }
\abx@aux@cite{0}{fujimoto2018addressingfunctionapproximationerror}
\abx@aux@segm{0}{0}{fujimoto2018addressingfunctionapproximationerror}
\abx@aux@cite{0}{kuznetsov2020controllingoverestimationbiastruncated}
\abx@aux@segm{0}{0}{kuznetsov2020controllingoverestimationbiastruncated}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Double TD Learning}{5}{subsection.2.4.2}\protected@file@percent }
\abx@aux@backref{4}{hasselt2010doubleqlearning}{0}{5}{5}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Méthodes pessimistes}{5}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}TD3}{5}{subsection.2.5.1}\protected@file@percent }
\abx@aux@backref{5}{fujimoto2018addressingfunctionapproximationerror}{0}{5}{5}
\abx@aux@cite{0}{dabney2017distributionalreinforcementlearningquantile}
\abx@aux@segm{0}{0}{dabney2017distributionalreinforcementlearningquantile}
\abx@aux@cite{0}{moskovitz2022tacticaloptimismpessimismdeep}
\abx@aux@segm{0}{0}{moskovitz2022tacticaloptimismpessimismdeep}
\abx@aux@cite{0}{ji2024seizingserendipityexploitingvalue}
\abx@aux@segm{0}{0}{ji2024seizingserendipityexploitingvalue}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}TQC}{6}{subsection.2.5.2}\protected@file@percent }
\abx@aux@backref{6}{kuznetsov2020controllingoverestimationbiastruncated}{0}{6}{6}
\abx@aux@backref{7}{dabney2017distributionalreinforcementlearningquantile}{0}{6}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}TOP}{6}{subsection.2.5.3}\protected@file@percent }
\abx@aux@backref{8}{moskovitz2022tacticaloptimismpessimismdeep}{0}{6}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}BAC}{7}{subsection.2.5.4}\protected@file@percent }
\abx@aux@backref{9}{ji2024seizingserendipityexploitingvalue}{0}{7}{7}
\abx@aux@cite{0}{haarnoja2019softactorcriticalgorithmsapplications}
\abx@aux@segm{0}{0}{haarnoja2019softactorcriticalgorithmsapplications}
\abx@aux@cite{0}{perringilbert2024afuactorfreecriticupdates}
\abx@aux@segm{0}{0}{perringilbert2024afuactorfreecriticupdates}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Contributions}{8}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Infrastructure}{8}{section.3.1}\protected@file@percent }
\abx@aux@backref{10}{haarnoja2019softactorcriticalgorithmsapplications}{0}{8}{8}
\abx@aux@backref{11}{perringilbert2024afuactorfreecriticupdates}{0}{8}{8}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Visualisations}{9}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Évolution des fonctions $Q(s,a)$, $V(s)$, $A(s,a)$ et $V(s)+ A(s,a)$ en fonction de l'action pour un état critique de MountainCar pendant l'entraînement d'AFU. Les courbes montrent la convergence progressive vers la forme attendue de la fonction valeur optimale.}}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:afu-evolution}{{3.1}{9}{Évolution des fonctions $Q(s,a)$, $V(s)$, $A(s,a)$ et $V(s)+ A(s,a)$ en fonction de l'action pour un état critique de MountainCar pendant l'entraînement d'AFU. Les courbes montrent la convergence progressive vers la forme attendue de la fonction valeur optimale}{figure.caption.2}{}}
\abx@aux@cite{0}{kuznetsov2020controllingoverestimationbiastruncated}
\abx@aux@segm{0}{0}{kuznetsov2020controllingoverestimationbiastruncated}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Vue d'ensemble de l'espace d'état MountainCar pendant l'entraînement : fonction $V(s)$, politique $\pi (s)$, états du replay buffer, enveloppe convexe (ligne noire) et trajectoires moyennes (points).}}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mountaincar-overview}{{3.2}{10}{Vue d'ensemble de l'espace d'état MountainCar pendant l'entraînement : fonction $V(s)$, politique $\pi (s)$, états du replay buffer, enveloppe convexe (ligne noire) et trajectoires moyennes (points)}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}La Figure 4 de l'article TQC}{10}{section.3.3}\protected@file@percent }
\abx@aux@backref{12}{kuznetsov2020controllingoverestimationbiastruncated}{0}{10}{10}
\abx@aux@cite{0}{mnih2015humanlevelcontroldeepreinforcement}
\abx@aux@segm{0}{0}{mnih2015humanlevelcontroldeepreinforcement}
\abx@aux@backref{13}{mnih2015humanlevelcontroldeepreinforcement}{0}{11}{11}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}AFU-TQC}{11}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Mesure du biais}{13}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Résultats expérimentaux}{14}{section.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Boîtes à moustaches montrant l'impact du paramètre qui contrôle le pessimisme sur le biais mesuré empiriquement sur MountainCar Continuous. Chaque boîte montre MIN/Q3/IQM/Q1/MAX. Dans l'ordre : MSAC, SAC, AFU, TQC, TOP.}}{15}{figure.caption.4}\protected@file@percent }
\newlabel{fig:bias-measurements}{{3.3}{15}{Boîtes à moustaches montrant l'impact du paramètre qui contrôle le pessimisme sur le biais mesuré empiriquement sur MountainCar Continuous. Chaque boîte montre MIN/Q3/IQM/Q1/MAX. Dans l'ordre : MSAC, SAC, AFU, TQC, TOP}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Évolution de la performance en fonction du temps pour chacune des approches. Le graphe est clair pour les approches « simples » type MSAC ou SAC et devient difficilement lisible pour les approches « complexes ». Dans l'ordre : MSAC, SAC, AFU, TQC, TOP.}}{16}{figure.caption.5}\protected@file@percent }
\newlabel{fig:performance-evolution}{{3.4}{16}{Évolution de la performance en fonction du temps pour chacune des approches. Le graphe est clair pour les approches « simples » type MSAC ou SAC et devient difficilement lisible pour les approches « complexes ». Dans l'ordre : MSAC, SAC, AFU, TQC, TOP}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Questions de recherche identifiées}{17}{section.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}AFU et biais de maximisation}{17}{subsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Corrélation biais-performance}{18}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Critique biaisé ou exploration}{18}{subsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conclusion}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\abx@aux@read@bbl@mdfivesum{D53F92D957D82F6C35DA29D3276A7F45}
\abx@aux@defaultrefcontext{0}{10.5555/3312046}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{sutton1999policygradientmethodsreinforcement}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{thrun1993issuesactionselection}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{hasselt2010doubleqlearning}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{fujimoto2018addressingfunctionapproximationerror}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kuznetsov2020controllingoverestimationbiastruncated}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{dabney2017distributionalreinforcementlearningquantile}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{moskovitz2022tacticaloptimismpessimismdeep}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ji2024seizingserendipityexploitingvalue}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{haarnoja2019softactorcriticalgorithmsapplications}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{perringilbert2024afuactorfreecriticupdates}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{mnih2015humanlevelcontroldeepreinforcement}{none/global//global/global/global}
\gdef \@abspage@last{23}
